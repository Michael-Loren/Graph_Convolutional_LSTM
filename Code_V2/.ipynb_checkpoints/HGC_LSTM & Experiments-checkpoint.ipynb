{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from Modules import FilterLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataset(speed_matrix, BATCH_SIZE = 40, seq_len = 10, pred_len = 1, train_propotion = 0.7, valid_propotion = 0.2):\n",
    "    \"\"\" Prepare training and testing datasets and dataloaders.\n",
    "    \n",
    "    Convert speed/volume/occupancy matrix to training and testing dataset. \n",
    "    The vertical axis of speed_matrix is the time axis and the horizontal axis \n",
    "    is the spatial axis.\n",
    "    \n",
    "    Args:\n",
    "        speed_matrix: a Matrix containing spatial-temporal speed data for a network\n",
    "        seq_len: length of input sequence\n",
    "        pred_len: length of predicted sequence\n",
    "    Returns:\n",
    "        Training dataloader\n",
    "        Testing dataloader\n",
    "    \"\"\"\n",
    "    time_len = speed_matrix.shape[0]\n",
    "    \n",
    "    max_speed = speed_matrix.max().max()\n",
    "    speed_matrix =  speed_matrix / max_speed\n",
    "    \n",
    "    speed_sequences, speed_labels = [], []\n",
    "    for i in range(time_len - seq_len - pred_len):\n",
    "        speed_sequences.append(speed_matrix.iloc[i:i+seq_len].values)\n",
    "        speed_labels.append(speed_matrix.iloc[i+seq_len:i+seq_len+pred_len].values)\n",
    "    speed_sequences, speed_labels = np.asarray(speed_sequences), np.asarray(speed_labels)\n",
    "    \n",
    "    # shuffle and split the dataset to training and testing datasets\n",
    "    sample_size = speed_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype = int)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * ( train_propotion + valid_propotion)))\n",
    "    \n",
    "    train_data, train_label = speed_sequences[:train_index], speed_labels[:train_index]\n",
    "    valid_data, valid_label = speed_sequences[train_index:valid_index], speed_labels[train_index:valid_index]\n",
    "    test_data, test_label = speed_sequences[valid_index:], speed_labels[valid_index:]\n",
    "    \n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "    \n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    \n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader, max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     data = 'inrix'\n",
    "    data = 'loop'\n",
    "    directory = '../../Data_Warehouse/Data_network_traffic/'\n",
    "    if data == 'inrix':\n",
    "        speed_matrix =  pd.read_pickle( directory + 'inrix_seattle_speed_matrix_2012')\n",
    "        A = np.load(directory + 'INRIX_Seattle_2012_A.npy')\n",
    "        FFR_5min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_5min.npy')\n",
    "        FFR_10min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_10min.npy')\n",
    "        FFR_15min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_15min.npy')\n",
    "        FFR_20min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_20min.npy')\n",
    "        FFR_25min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_25min.npy')\n",
    "        FFR = [FFR_5min, FFR_10min, FFR_15min, FFR_20min, FFR_25min]\n",
    "    elif data == 'loop':\n",
    "        speed_matrix =  pd.read_pickle( directory + 'speed_matrix_2015')\n",
    "        A = np.load( directory + 'Loop_Seattle_2015_A.npy')\n",
    "        FFR_5min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_5min.npy')\n",
    "        FFR_10min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_10min.npy')\n",
    "        FFR_15min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_15min.npy')\n",
    "        FFR_20min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_20min.npy')\n",
    "        FFR_25min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_25min.npy')\n",
    "        FFR = [FFR_5min, FFR_10min, FFR_15min, FFR_20min, FFR_25min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader, max_speed = PrepareDataset(speed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "[batch_size, step_size, fea_size] = inputs.size()\n",
    "input_dim = fea_size\n",
    "hidden_dim = fea_size\n",
    "output_dim = fea_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate = 1e-5, num_epochs = 300, patience = 10, min_delta = 0.00001):\n",
    "    \n",
    "    inputs, labels = next(iter(train_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "    input_dim = fea_size\n",
    "    hidden_dim = fea_size\n",
    "    output_dim = fea_size\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#         print('-' * 10)\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else: \n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                \n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            \n",
    "            losses_train.append(loss_train.data)\n",
    "            losses_epoch_train.append(loss_train.data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # validation \n",
    "            try: \n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs_val, labels_val = Variable(inputs_val.cuda()), Variable(labels_val.cuda())\n",
    "            else: \n",
    "                inputs_val, labels_val = Variable(inputs_val), Variable(labels_val)\n",
    "\n",
    "            outputs_val= model(inputs_val)\n",
    "\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val))\n",
    "            losses_valid.append(loss_valid.data)\n",
    "            losses_epoch_valid.append(loss_valid.data)\n",
    "            \n",
    "            # output\n",
    "            trained_number += 1\n",
    "            \n",
    "        avg_losses_epoch_train = sum(losses_epoch_train) / float(len(losses_epoch_train))\n",
    "        avg_losses_epoch_valid = sum(losses_epoch_valid) / float(len(losses_epoch_valid))\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format( \\\n",
    "                epoch, \\\n",
    "                np.around(avg_losses_epoch_train.cpu().numpy(), decimals=8),\\\n",
    "                np.around(avg_losses_epoch_valid.cpu().numpy(), decimals=8),\\\n",
    "                np.around([cur_time - pre_time] , decimals=2),\\\n",
    "                is_best_model) )\n",
    "        pre_time = cur_time\n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \n",
    "    inputs, labels = next(iter(test_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.MSELoss()\n",
    "    \n",
    "    tested_batch = 0\n",
    "    \n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else: \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "\n",
    "        outputs = None\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    \n",
    "        loss_MSE = torch.nn.MSELoss()\n",
    "        loss_L1 = torch.nn.L1Loss()\n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "    \n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "    \n",
    "        tested_batch += 1\n",
    "    \n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.conv = nn.Conv1d(1, hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "        conv = self.conv(input)\n",
    "        \n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizedSpectralGraphConvolution(nn.Module):\n",
    "    def __init__(self, A, K):\n",
    "        \n",
    "        super(LocalizedSpectralGraphConvolution, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A.cuda()\n",
    "        feature_size = A.shape[0]\n",
    "        self.D = torch.diag(torch.sum(self.A, dim=0)).cuda()\n",
    "        \n",
    "        I = torch.eye(feature_size,feature_size).cuda()\n",
    "        self.L = I - torch.inverse(torch.sqrt(self.D)).matmul(self.A).matmul(torch.inverse(torch.sqrt(self.D))) \n",
    "        \n",
    "        L_temp = I\n",
    "        for i in range(K):\n",
    "            L_temp = torch.matmul(L_temp, self.L)\n",
    "            if i == 0:\n",
    "                self.L_tensor = torch.unsqueeze(L_temp, 2)\n",
    "            else:\n",
    "                self.L_tensor = torch.cat((self.L_tensor, torch.unsqueeze(L_temp, 2)), 2)\n",
    "            \n",
    "        self.L_tensor = Variable(self.L_tensor.cuda(), requires_grad=False)\n",
    "\n",
    "        self.params = Parameter(torch.FloatTensor(K).cuda())\n",
    "        \n",
    "        stdv = 1. / math.sqrt(K)\n",
    "        for i in range(K):\n",
    "            self.params[i].data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "\n",
    "        conv = x.matmul( torch.sum(self.params.expand_as(self.L_tensor) * self.L_tensor, 2) )\n",
    "\n",
    "        return conv\n",
    "        \n",
    "        \n",
    "class LocalizedSpectralGraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(LocalizedSpectralGraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.gconv = LocalizedSpectralGraphConvolution(A, K)\n",
    "    \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size + hidden_size\n",
    "\n",
    "        self.fl = nn.Linear(input_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "#         conv_sample_start = time.time()  \n",
    "        conv = F.relu(self.gconv(input))\n",
    "#         conv_sample_end = time.time()  \n",
    "#         print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "#         print(type(outputs))\n",
    "        \n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralGraphConvolution(nn.Module):\n",
    "    def __init__(self, A):\n",
    "        \n",
    "        super(SpectralGraphConvolution, self).__init__()\n",
    "        \n",
    "        feature_size = A.shape[0]\n",
    "        \n",
    "        self.A = A\n",
    "        self.D = torch.diag(torch.sum(self.A, dim=0))\n",
    "        self.L = self.D - A\n",
    "        self.param = Parameter(torch.FloatTensor(feature_size).cuda())\n",
    "        stdv = 1. / math.sqrt(feature_size)\n",
    "        self.param.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        self.e, self.v = torch.linalg.eig(self.L)\n",
    "        self.vt = torch.conj(torch.transpose(self.v, -2, -1))\n",
    "        self.v = Variable(self.v.cuda(), requires_grad=False)\n",
    "        self.vt = Variable(self.vt.cuda(), requires_grad=False)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        conv_sample_start = time.time()  \n",
    "        real_part = x.matmul(self.v.real.matmul(torch.diag(self.param)).matmul(self.vt.real))\n",
    "        imag_part = x.matmul(self.v.imag.matmul(torch.diag(self.param)).matmul(self.vt.imag))\n",
    "        conv = real_part - imag_part\n",
    "        conv_sample_end = time.time()  \n",
    "        print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        return conv\n",
    "        \n",
    "class SpectralGraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(SpectralGraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.gconv = SpectralGraphConvolution(A)\n",
    "    \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size + hidden_size\n",
    "\n",
    "        self.fl = nn.Linear(input_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        conv_sample_start = time.time()  \n",
    "        conv = self.gconv(input)\n",
    "        conv_sample_end = time.time()  \n",
    "        print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        train_sample_start = time.time()  \n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "        \n",
    "        train_sample_end = time.time()\n",
    "        print('train sample:' , (train_sample_end - train_sample_start))\n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, FFR, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(GraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        \n",
    "        self.A_list = [] # Adjacency Matrix List\n",
    "        A = torch.FloatTensor(A)\n",
    "        A_temp = torch.eye(feature_size,feature_size)\n",
    "        for i in range(K):\n",
    "            A_temp = torch.matmul(A_temp, torch.Tensor(A))\n",
    "            if Clamp_A:\n",
    "                # confine elements of A \n",
    "                A_temp = torch.clamp(A_temp, max = 1.) \n",
    "            self.A_list.append(torch.mul(A_temp, torch.Tensor(FFR)))\n",
    "#             self.A_list.append(A_temp)\n",
    "        \n",
    "        # a length adjustable Module List for hosting all graph convolutions\n",
    "        self.gc_list = nn.ModuleList([FilterLinear(feature_size, feature_size, self.A_list[i], bias=False) for i in range(K)])                  \n",
    "        \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size * K\n",
    "\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        # initialize the neighbor weight for the cell state\n",
    "        self.Neighbor_weight = Parameter(torch.FloatTensor(feature_size))\n",
    "        stdv = 1. / math.sqrt(feature_size)\n",
    "        self.Neighbor_weight.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "        x = input\n",
    "\n",
    "        gc = self.gc_list[0](x)\n",
    "        for i in range(1, self.K):\n",
    "            gc = torch.cat((gc, self.gc_list[i](x)), 1)\n",
    "            \n",
    "        combined = torch.cat((gc, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "\n",
    "        NC = torch.mul(Cell_State,  torch.mv(Variable(self.A_list[-1], requires_grad=False).cuda(), self.Neighbor_weight))\n",
    "        Cell_State = f * NC + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "\n",
    "        return Hidden_State, Cell_State, gc\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State, gc = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "        \n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.007217090111225843, valid_loss: 0.007448929827660322, time: [18.65], best model: 1\n",
      "Tested: L1_mean: 4.731986668644843, L1_std : 0.3922757104047296\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_dim, hidden_dim, output_dim, output_last = True)\n",
    "lstm, lstm_loss = TrainModel(lstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "lstm_test = TestModel(lstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.3345490097999573, valid_loss: 0.3274995982646942, time: [23.99], best model: 1\n",
      "Tested: L1_mean: 77.01383447029208, L1_std : 1.1781853830700637\n"
     ]
    }
   ],
   "source": [
    "K = 64\n",
    "Clamp_A = False\n",
    "lsgclstm = LocalizedSpectralGraphConvolutionalLSTM(K, torch.Tensor(A), A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "lsgclstm, lsgclstm_loss = TrainModel(lsgclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "lsgclstm_test = TestModel(lsgclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "back_length = 3\n",
    "Clamp_A = False\n",
    "sgclstm = SpectralGraphConvolutionalLSTM(K, torch.Tensor(A), A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "sgclstm, sgclstm_loss = TrainModel(sgclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "sgclstm_test = TestModel(sgclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.003434400074183941, valid_loss: 0.0037780199199914932, time: [30.73], best model: 1\n",
      "Tested: L1_mean: 4.186735011515973, L1_std : 0.2874489577276646\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "back_length = 3\n",
    "Clamp_A = False\n",
    "gclstm = GraphConvolutionalLSTM(K, torch.Tensor(A), FFR[back_length], A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "gclstm, gclstm_loss = TrainModel(gclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "gclstm_test = TestModel(gclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn_val_loss = np.asarray(rnn_loss[3])\n",
    "lstm_val_loss = np.asarray(lstm_loss[3][0].cpu())\n",
    "hgclstm_val_loss = np.asarray(gclstm_loss[3][0].cpu())\n",
    "lsgclstm_val_loss = np.asarray(lsgclstm_loss[3][0].cpu())\n",
    "sgclstm_val_loss = np.asarray(sgclstm_loss[3][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_val_loss = np.load('lstm_val_loss.npy')\n",
    "# hgclstm_val_loss = np.load('hgclstm_val_loss.npy')\n",
    "# lsgclstm_val_loss = np.load('lsgclstm_val_loss.npy')\n",
    "# sgclstm_val_loss = np.load('sgclstm_val_loss.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('lstm_val_loss', lstm_val_loss)\n",
    "# np.save('hgclstm_val_loss', gclstm_val_loss)\n",
    "# np.save('lsgclstm_val_loss', lsgclstm_val_loss)\n",
    "# np.save('sgclstm_val_loss', sgclstm_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_val_loss = lstm_val_loss.flatten()\n",
    "hgclstm_val_loss = hgclstm_val_loss.flatten()\n",
    "lsgclstm_val_loss = lsgclstm_val_loss.flatten()\n",
    "sgclstm_val_loss = sgclstm_val_loss.flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.plot(np.arange(1, len(lstm_val_loss) + 1), lstm_val_loss,  label = 'LSTM')\n",
    "plt.plot(np.arange(1, len(sgclstm_val_loss) + 1), sgclstm_val_loss,  label = 'SGC+LSTM')\n",
    "plt.plot(np.arange(1, len(lsgclstm_val_loss) + 1), lsgclstm_val_loss,  label = 'LSGC+LSTM')\n",
    "plt.plot(np.arange(1, len(hgclstm_val_loss) + 1),hgclstm_val_loss,  label = 'HGC-LSTM')\n",
    "plt.ylim((6 * 0.0001, 0.4))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Validation Loss (MSE)', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, which='both')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('Validation_loss.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
