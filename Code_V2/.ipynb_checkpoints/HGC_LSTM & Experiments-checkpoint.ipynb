{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from Modules import FilterLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataset(speed_matrix, BATCH_SIZE = 40, seq_len = 10, pred_len = 1, train_propotion = 0.7, valid_propotion = 0.2):\n",
    "    \"\"\" Prepare training and testing datasets and dataloaders.\n",
    "    \n",
    "    Convert speed/volume/occupancy matrix to training and testing dataset. \n",
    "    The vertical axis of speed_matrix is the time axis and the horizontal axis \n",
    "    is the spatial axis.\n",
    "    \n",
    "    Args:\n",
    "        speed_matrix: a Matrix containing spatial-temporal speed data for a network\n",
    "        seq_len: length of input sequence\n",
    "        pred_len: length of predicted sequence\n",
    "    Returns:\n",
    "        Training dataloader\n",
    "        Testing dataloader\n",
    "    \"\"\"\n",
    "    time_len = speed_matrix.shape[0]\n",
    "    \n",
    "    max_speed = speed_matrix.max().max()\n",
    "    speed_matrix =  speed_matrix / max_speed\n",
    "    \n",
    "    speed_sequences, speed_labels = [], []\n",
    "    for i in range(time_len - seq_len - pred_len):\n",
    "        speed_sequences.append(speed_matrix.iloc[i:i+seq_len].values)\n",
    "        speed_labels.append(speed_matrix.iloc[i+seq_len:i+seq_len+pred_len].values)\n",
    "    speed_sequences, speed_labels = np.asarray(speed_sequences), np.asarray(speed_labels)\n",
    "    \n",
    "    # shuffle and split the dataset to training and testing datasets\n",
    "    sample_size = speed_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype = int)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * ( train_propotion + valid_propotion)))\n",
    "    \n",
    "    train_data, train_label = speed_sequences[:train_index], speed_labels[:train_index]\n",
    "    valid_data, valid_label = speed_sequences[train_index:valid_index], speed_labels[train_index:valid_index]\n",
    "    test_data, test_label = speed_sequences[valid_index:], speed_labels[valid_index:]\n",
    "    \n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "    \n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    \n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader, max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     data = 'inrix'\n",
    "    data = 'loop'\n",
    "    directory = '../../Data_Warehouse/Data_network_traffic/'\n",
    "    if data == 'inrix':\n",
    "        speed_matrix =  pd.read_pickle( directory + 'inrix_seattle_speed_matrix_2012')\n",
    "        A = np.load(directory + 'INRIX_Seattle_2012_A.npy')\n",
    "        FFR_5min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_5min.npy')\n",
    "        FFR_10min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_10min.npy')\n",
    "        FFR_15min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_15min.npy')\n",
    "        FFR_20min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_20min.npy')\n",
    "        FFR_25min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_25min.npy')\n",
    "        FFR = [FFR_5min, FFR_10min, FFR_15min, FFR_20min, FFR_25min]\n",
    "    elif data == 'loop':\n",
    "        speed_matrix =  pd.read_pickle( directory + 'speed_matrix_2015')\n",
    "        A = np.load( directory + 'Loop_Seattle_2015_A.npy')\n",
    "        FFR_5min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_5min.npy')\n",
    "        FFR_10min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_10min.npy')\n",
    "        FFR_15min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_15min.npy')\n",
    "        FFR_20min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_20min.npy')\n",
    "        FFR_25min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_25min.npy')\n",
    "        FFR = [FFR_5min, FFR_10min, FFR_15min, FFR_20min, FFR_25min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader, max_speed = PrepareDataset(speed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "[batch_size, step_size, fea_size] = inputs.size()\n",
    "input_dim = fea_size\n",
    "hidden_dim = fea_size\n",
    "output_dim = fea_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate = 1e-5, num_epochs = 300, patience = 10, min_delta = 0.00001):\n",
    "    \n",
    "    inputs, labels = next(iter(train_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "    input_dim = fea_size\n",
    "    hidden_dim = fea_size\n",
    "    output_dim = fea_size\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#         print('-' * 10)\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else: \n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                \n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            \n",
    "            losses_train.append(loss_train.data)\n",
    "            losses_epoch_train.append(loss_train.data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # validation \n",
    "            try: \n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs_val, labels_val = Variable(inputs_val.cuda()), Variable(labels_val.cuda())\n",
    "            else: \n",
    "                inputs_val, labels_val = Variable(inputs_val), Variable(labels_val)\n",
    "\n",
    "            outputs_val= model(inputs_val)\n",
    "\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val))\n",
    "            losses_valid.append(loss_valid.data)\n",
    "            losses_epoch_valid.append(loss_valid.data)\n",
    "            \n",
    "            # output\n",
    "            trained_number += 1\n",
    "            \n",
    "        avg_losses_epoch_train = sum(losses_epoch_train) / float(len(losses_epoch_train))\n",
    "        avg_losses_epoch_valid = sum(losses_epoch_valid) / float(len(losses_epoch_valid))\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format( \\\n",
    "                epoch, \\\n",
    "                np.around(avg_losses_epoch_train.cpu().numpy(), decimals=8),\\\n",
    "                np.around(avg_losses_epoch_valid.cpu().numpy(), decimals=8),\\\n",
    "                np.around([cur_time - pre_time] , decimals=2),\\\n",
    "                is_best_model) )\n",
    "        pre_time = cur_time\n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \n",
    "    inputs, labels = next(iter(test_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.MSELoss()\n",
    "    \n",
    "    tested_batch = 0\n",
    "    \n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else: \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "\n",
    "        outputs = None\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    \n",
    "        loss_MSE = torch.nn.MSELoss()\n",
    "        loss_L1 = torch.nn.L1Loss()\n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "    \n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "    \n",
    "        tested_batch += 1\n",
    "    \n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.conv = nn.Conv1d(1, hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "        conv = self.conv(input)\n",
    "        \n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizedSpectralGraphConvolution(nn.Module):\n",
    "    def __init__(self, A, K):\n",
    "        \n",
    "        super(LocalizedSpectralGraphConvolution, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A.cuda()\n",
    "        feature_size = A.shape[0]\n",
    "        self.D = torch.diag(torch.sum(self.A, dim=0)).cuda()\n",
    "        \n",
    "        I = torch.eye(feature_size,feature_size).cuda()\n",
    "        self.L = I - torch.inverse(torch.sqrt(self.D)).matmul(self.A).matmul(torch.inverse(torch.sqrt(self.D))) \n",
    "        \n",
    "        L_temp = I\n",
    "        for i in range(K):\n",
    "            L_temp = torch.matmul(L_temp, self.L)\n",
    "            if i == 0:\n",
    "                self.L_tensor = torch.unsqueeze(L_temp, 2)\n",
    "            else:\n",
    "                self.L_tensor = torch.cat((self.L_tensor, torch.unsqueeze(L_temp, 2)), 2)\n",
    "            \n",
    "        self.L_tensor = Variable(self.L_tensor.cuda(), requires_grad=False)\n",
    "\n",
    "        self.params = Parameter(torch.FloatTensor(K).cuda())\n",
    "        \n",
    "        stdv = 1. / math.sqrt(K)\n",
    "        for i in range(K):\n",
    "            self.params[i].data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "\n",
    "        conv = x.matmul( torch.sum(self.params.expand_as(self.L_tensor) * self.L_tensor, 2) )\n",
    "\n",
    "        return conv\n",
    "        \n",
    "        \n",
    "class LocalizedSpectralGraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(LocalizedSpectralGraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.gconv = LocalizedSpectralGraphConvolution(A, K)\n",
    "    \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size + hidden_size\n",
    "\n",
    "        self.fl = nn.Linear(input_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "#         conv_sample_start = time.time()  \n",
    "        conv = F.relu(self.gconv(input))\n",
    "#         conv_sample_end = time.time()  \n",
    "#         print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "#         print(type(outputs))\n",
    "        \n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralGraphConvolution(nn.Module):\n",
    "    def __init__(self, A):\n",
    "        \n",
    "        super(SpectralGraphConvolution, self).__init__()\n",
    "        \n",
    "        feature_size = A.shape[0]\n",
    "        \n",
    "        self.A = A\n",
    "        self.D = torch.diag(torch.sum(self.A, dim=0))\n",
    "        self.L = self.D - A\n",
    "        self.param = Parameter(torch.FloatTensor(feature_size).cuda())\n",
    "        stdv = 1. / math.sqrt(feature_size)\n",
    "        self.param.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        self.e, self.v = torch.linalg.eig(self.L)\n",
    "        self.vt = torch.conj(torch.transpose(self.v, -2, -1))\n",
    "        self.v = Variable(self.v.cuda(), requires_grad=False)\n",
    "        self.vt = Variable(self.vt.cuda(), requires_grad=False)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        conv_sample_start = time.time()  \n",
    "        real_part = x.matmul(self.v.real.matmul(torch.diag(self.param)).matmul(self.vt.real))\n",
    "        imag_part = x.matmul(self.v.imag.matmul(torch.diag(self.param)).matmul(self.vt.imag))\n",
    "        conv = real_part - imag_part\n",
    "        conv_sample_end = time.time()  \n",
    "        print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        return conv\n",
    "        \n",
    "class SpectralGraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(SpectralGraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.gconv = SpectralGraphConvolution(A)\n",
    "    \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size + hidden_size\n",
    "\n",
    "        self.fl = nn.Linear(input_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        conv_sample_start = time.time()  \n",
    "        conv = self.gconv(input)\n",
    "        conv_sample_end = time.time()  \n",
    "        print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        train_sample_start = time.time()  \n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "        \n",
    "        train_sample_end = time.time()\n",
    "        print('train sample:' , (train_sample_end - train_sample_start))\n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, FFR, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(GraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        \n",
    "        self.A_list = [] # Adjacency Matrix List\n",
    "        A = torch.FloatTensor(A)\n",
    "        A_temp = torch.eye(feature_size,feature_size)\n",
    "        for i in range(K):\n",
    "            A_temp = torch.matmul(A_temp, torch.Tensor(A))\n",
    "            if Clamp_A:\n",
    "                # confine elements of A \n",
    "                A_temp = torch.clamp(A_temp, max = 1.) \n",
    "            self.A_list.append(torch.mul(A_temp, torch.Tensor(FFR)))\n",
    "#             self.A_list.append(A_temp)\n",
    "        \n",
    "        # a length adjustable Module List for hosting all graph convolutions\n",
    "        self.gc_list = nn.ModuleList([FilterLinear(feature_size, feature_size, self.A_list[i], bias=False) for i in range(K)])                  \n",
    "        \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size * K\n",
    "\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        # initialize the neighbor weight for the cell state\n",
    "        self.Neighbor_weight = Parameter(torch.FloatTensor(feature_size))\n",
    "        stdv = 1. / math.sqrt(feature_size)\n",
    "        self.Neighbor_weight.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "        x = input\n",
    "\n",
    "        gc = self.gc_list[0](x)\n",
    "        for i in range(1, self.K):\n",
    "            gc = torch.cat((gc, self.gc_list[i](x)), 1)\n",
    "            \n",
    "        combined = torch.cat((gc, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "\n",
    "        NC = torch.mul(Cell_State,  torch.mv(Variable(self.A_list[-1], requires_grad=False).cuda(), self.Neighbor_weight))\n",
    "        Cell_State = f * NC + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "\n",
    "        return Hidden_State, Cell_State, gc\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State, gc = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "        \n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.007217090111225843, valid_loss: 0.007448929827660322, time: [18.65], best model: 1\n",
      "Tested: L1_mean: 4.731986668644843, L1_std : 0.3922757104047296\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_dim, hidden_dim, output_dim, output_last = True)\n",
    "lstm, lstm_loss = TrainModel(lstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "lstm_test = TestModel(lstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.3345490097999573, valid_loss: 0.3274995982646942, time: [23.99], best model: 1\n",
      "Tested: L1_mean: 77.01383447029208, L1_std : 1.1781853830700637\n"
     ]
    }
   ],
   "source": [
    "K = 64\n",
    "Clamp_A = False\n",
    "lsgclstm = LocalizedSpectralGraphConvolutionalLSTM(K, torch.Tensor(A), A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "lsgclstm, lsgclstm_loss = TrainModel(lsgclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "lsgclstm_test = TestModel(lsgclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "back_length = 3\n",
    "Clamp_A = False\n",
    "sgclstm = SpectralGraphConvolutionalLSTM(K, torch.Tensor(A), A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "sgclstm, sgclstm_loss = TrainModel(sgclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "sgclstm_test = TestModel(sgclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.003434400074183941, valid_loss: 0.0037780199199914932, time: [30.73], best model: 1\n",
      "Tested: L1_mean: 4.186735011515973, L1_std : 0.2874489577276646\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "back_length = 3\n",
    "Clamp_A = False\n",
    "gclstm = GraphConvolutionalLSTM(K, torch.Tensor(A), FFR[back_length], A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "gclstm, gclstm_loss = TrainModel(gclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "gclstm_test = TestModel(gclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn_val_loss = np.asarray(rnn_loss[3])\n",
    "lstm_val_loss = np.asarray(lstm_loss[3][0].cpu())\n",
    "hgclstm_val_loss = np.asarray(gclstm_loss[3][0].cpu())\n",
    "lsgclstm_val_loss = np.asarray(lsgclstm_loss[3][0].cpu())\n",
    "sgclstm_val_loss = np.asarray(sgclstm_loss[3][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_val_loss = np.load('lstm_val_loss.npy')\n",
    "hgclstm_val_loss = np.load('hgclstm_val_loss.npy')\n",
    "lsgclstm_val_loss = np.load('lsgclstm_val_loss.npy')\n",
    "sgclstm_val_loss = np.load('sgclstm_val_loss.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lstm_val_loss', lstm_val_loss)\n",
    "np.save('hgclstm_val_loss', hgclstm_val_loss)\n",
    "np.save('lsgclstm_val_loss', lsgclstm_val_loss)\n",
    "np.save('sgclstm_val_loss', sgclstm_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.plot(lstm_val_loss,  label = 'LSTM')\n",
    "plt.plot(sgclstm_val_loss,  label = 'SGC+LSTM')\n",
    "plt.plot(lsgclstm_val_loss,  label = 'LSGC+LSTM')\n",
    "plt.plot(hgclstm_val_loss,  label = 'HGC-LSTM')\n",
    "plt.ylim((6 * 0.0001, 0.4))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Validation Loss (MSE)', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, which='both')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('Validation_loss.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
