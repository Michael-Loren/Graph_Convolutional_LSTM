{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from Modules import FilterLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataset(speed_matrix, BATCH_SIZE = 40, seq_len = 10, pred_len = 1, train_propotion = 0.7, valid_propotion = 0.2):\n",
    "    \"\"\" Prepare training and testing datasets and dataloaders.\n",
    "    \n",
    "    Convert speed/volume/occupancy matrix to training and testing dataset. \n",
    "    The vertical axis of speed_matrix is the time axis and the horizontal axis \n",
    "    is the spatial axis.\n",
    "    \n",
    "    Args:\n",
    "        speed_matrix: a Matrix containing spatial-temporal speed data for a network\n",
    "        seq_len: length of input sequence\n",
    "        pred_len: length of predicted sequence\n",
    "    Returns:\n",
    "        Training dataloader\n",
    "        Testing dataloader\n",
    "    \"\"\"\n",
    "    time_len = speed_matrix.shape[0]\n",
    "    \n",
    "    max_speed = speed_matrix.max().max()\n",
    "    speed_matrix =  speed_matrix / max_speed\n",
    "    \n",
    "    speed_sequences, speed_labels = [], []\n",
    "    for i in range(time_len - seq_len - pred_len):\n",
    "        speed_sequences.append(speed_matrix.iloc[i:i+seq_len].values)\n",
    "        speed_labels.append(speed_matrix.iloc[i+seq_len:i+seq_len+pred_len].values)\n",
    "    speed_sequences, speed_labels = np.asarray(speed_sequences), np.asarray(speed_labels)\n",
    "    \n",
    "    # shuffle and split the dataset to training and testing datasets\n",
    "    sample_size = speed_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype = int)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * ( train_propotion + valid_propotion)))\n",
    "    \n",
    "    train_data, train_label = speed_sequences[:train_index], speed_labels[:train_index]\n",
    "    valid_data, valid_label = speed_sequences[train_index:valid_index], speed_labels[train_index:valid_index]\n",
    "    test_data, test_label = speed_sequences[valid_index:], speed_labels[valid_index:]\n",
    "    \n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "    \n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    \n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader, max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     data = 'inrix'\n",
    "    data = 'loop'\n",
    "    directory = '../../Data_Warehouse/Data_network_traffic/'\n",
    "    if data == 'inrix':\n",
    "        speed_matrix =  pd.read_pickle( directory + 'inrix_seattle_speed_matrix_2012')\n",
    "        A = np.load(directory + 'INRIX_Seattle_2012_A.npy')\n",
    "        FFR_5min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_5min.npy')\n",
    "        FFR_10min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_10min.npy')\n",
    "        FFR_15min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_15min.npy')\n",
    "        FFR_20min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_20min.npy')\n",
    "        FFR_25min = np.load(directory + 'INRIX_Seattle_2012_reachability_free_flow_25min.npy')\n",
    "        FFR = [FFR_5min, FFR_10min, FFR_15min, FFR_20min, FFR_25min]\n",
    "    elif data == 'loop':\n",
    "        speed_matrix =  pd.read_pickle( directory + 'speed_matrix_2015')\n",
    "        A = np.load( directory + 'Loop_Seattle_2015_A.npy')\n",
    "        FFR_5min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_5min.npy')\n",
    "        FFR_10min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_10min.npy')\n",
    "        FFR_15min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_15min.npy')\n",
    "        FFR_20min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_20min.npy')\n",
    "        FFR_25min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_25min.npy')\n",
    "        FFR = [FFR_5min, FFR_10min, FFR_15min, FFR_20min, FFR_25min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader, max_speed = PrepareDataset(speed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "[batch_size, step_size, fea_size] = inputs.size()\n",
    "input_dim = fea_size\n",
    "hidden_dim = fea_size\n",
    "output_dim = fea_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate = 1e-5, num_epochs = 300, patience = 10, min_delta = 0.00001):\n",
    "    \n",
    "    inputs, labels = next(iter(train_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "    input_dim = fea_size\n",
    "    hidden_dim = fea_size\n",
    "    output_dim = fea_size\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#         print('-' * 10)\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else: \n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                \n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            \n",
    "            losses_train.append(loss_train.data)\n",
    "            losses_epoch_train.append(loss_train.data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # validation \n",
    "            try: \n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs_val, labels_val = Variable(inputs_val.cuda()), Variable(labels_val.cuda())\n",
    "            else: \n",
    "                inputs_val, labels_val = Variable(inputs_val), Variable(labels_val)\n",
    "\n",
    "            outputs_val= model(inputs_val)\n",
    "\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val))\n",
    "            losses_valid.append(loss_valid.data)\n",
    "            losses_epoch_valid.append(loss_valid.data)\n",
    "            \n",
    "            # output\n",
    "            trained_number += 1\n",
    "            \n",
    "        avg_losses_epoch_train = sum(losses_epoch_train) / float(len(losses_epoch_train))\n",
    "        avg_losses_epoch_valid = sum(losses_epoch_valid) / float(len(losses_epoch_valid))\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format( \\\n",
    "                epoch, \\\n",
    "                np.around(avg_losses_epoch_train.cpu().numpy(), decimals=8),\\\n",
    "                np.around(avg_losses_epoch_valid.cpu().numpy(), decimals=8),\\\n",
    "                np.around([cur_time - pre_time] , decimals=2),\\\n",
    "                is_best_model) )\n",
    "        pre_time = cur_time\n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \n",
    "    inputs, labels = next(iter(test_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.MSELoss()\n",
    "    \n",
    "    tested_batch = 0\n",
    "    \n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    \n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else: \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "\n",
    "        outputs = None\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    \n",
    "        loss_MSE = torch.nn.MSELoss()\n",
    "        loss_L1 = torch.nn.L1Loss()\n",
    "        loss_mse = loss_MSE(outputs, torch.squeeze(labels))\n",
    "        loss_l1 = loss_L1(outputs, torch.squeeze(labels))\n",
    "    \n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "    \n",
    "        tested_batch += 1\n",
    "    \n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    \n",
    "    print('Tested: L1_mean: {}, L1_std : {}'.format(mean_l1, std_l1))\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.conv = nn.Conv1d(1, hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "        conv = self.conv(input)\n",
    "        \n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizedSpectralGraphConvolution(nn.Module):\n",
    "    def __init__(self, A, K):\n",
    "        \n",
    "        super(LocalizedSpectralGraphConvolution, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A.cuda()\n",
    "        feature_size = A.shape[0]\n",
    "        self.D = torch.diag(torch.sum(self.A, dim=0)).cuda()\n",
    "        \n",
    "        I = torch.eye(feature_size,feature_size).cuda()\n",
    "        self.L = I - torch.inverse(torch.sqrt(self.D)).matmul(self.A).matmul(torch.inverse(torch.sqrt(self.D))) \n",
    "        \n",
    "        L_temp = I\n",
    "        for i in range(K):\n",
    "            L_temp = torch.matmul(L_temp, self.L)\n",
    "            if i == 0:\n",
    "                self.L_tensor = torch.unsqueeze(L_temp, 2)\n",
    "            else:\n",
    "                self.L_tensor = torch.cat((self.L_tensor, torch.unsqueeze(L_temp, 2)), 2)\n",
    "            \n",
    "        self.L_tensor = Variable(self.L_tensor.cuda(), requires_grad=False)\n",
    "\n",
    "        self.params = Parameter(torch.FloatTensor(K).cuda())\n",
    "        \n",
    "        stdv = 1. / math.sqrt(K)\n",
    "        for i in range(K):\n",
    "            self.params[i].data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "\n",
    "        conv = x.matmul( torch.sum(self.params.expand_as(self.L_tensor) * self.L_tensor, 2) )\n",
    "\n",
    "        return conv\n",
    "        \n",
    "        \n",
    "class LocalizedSpectralGraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(LocalizedSpectralGraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.gconv = LocalizedSpectralGraphConvolution(A, K)\n",
    "    \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size + hidden_size\n",
    "\n",
    "        self.fl = nn.Linear(input_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "#         conv_sample_start = time.time()  \n",
    "        conv = F.relu(self.gconv(input))\n",
    "#         conv_sample_end = time.time()  \n",
    "#         print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "#         print(type(outputs))\n",
    "        \n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralGraphConvolution(nn.Module):\n",
    "    def __init__(self, A):\n",
    "        \n",
    "        super(SpectralGraphConvolution, self).__init__()\n",
    "        \n",
    "        feature_size = A.shape[0]\n",
    "        \n",
    "        self.A = A\n",
    "        self.D = torch.diag(torch.sum(self.A, dim=0))\n",
    "        self.L = self.D - A\n",
    "        self.param = Parameter(torch.FloatTensor(feature_size).cuda())\n",
    "        stdv = 1. / math.sqrt(feature_size)\n",
    "        self.param.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        self.e, self.v = torch.linalg.eig(self.L)\n",
    "        self.vt = torch.conj(torch.transpose(self.v, -2, -1))\n",
    "        self.v = Variable(self.v.cuda(), requires_grad=False)\n",
    "        self.vt = Variable(self.vt.cuda(), requires_grad=False)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        conv_sample_start = time.time()  \n",
    "        real_part = x.matmul(self.v.real.matmul(torch.diag(self.param)).matmul(self.vt.real))\n",
    "        imag_part = x.matmul(self.v.imag.matmul(torch.diag(self.param)).matmul(self.vt.imag))\n",
    "        conv = real_part - imag_part\n",
    "        conv_sample_end = time.time()  \n",
    "        # print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        return conv\n",
    "        \n",
    "class SpectralGraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(SpectralGraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.gconv = SpectralGraphConvolution(A)\n",
    "    \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size + hidden_size\n",
    "\n",
    "        self.fl = nn.Linear(input_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        conv_sample_start = time.time()  \n",
    "        conv = self.gconv(input)\n",
    "        conv_sample_end = time.time()  \n",
    "        # print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        train_sample_start = time.time()  \n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "        \n",
    "        train_sample_end = time.time()\n",
    "        # print('train sample:' , (train_sample_end - train_sample_start))\n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, FFR, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(GraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        \n",
    "        self.A_list = [] # Adjacency Matrix List\n",
    "        A = torch.FloatTensor(A)\n",
    "        A_temp = torch.eye(feature_size,feature_size)\n",
    "        for i in range(K):\n",
    "            A_temp = torch.matmul(A_temp, torch.Tensor(A))\n",
    "            if Clamp_A:\n",
    "                # confine elements of A \n",
    "                A_temp = torch.clamp(A_temp, max = 1.) \n",
    "            self.A_list.append(torch.mul(A_temp, torch.Tensor(FFR)))\n",
    "#             self.A_list.append(A_temp)\n",
    "        \n",
    "        # a length adjustable Module List for hosting all graph convolutions\n",
    "        self.gc_list = nn.ModuleList([FilterLinear(feature_size, feature_size, self.A_list[i], bias=False) for i in range(K)])                  \n",
    "        \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size * K\n",
    "\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        # initialize the neighbor weight for the cell state\n",
    "        self.Neighbor_weight = Parameter(torch.FloatTensor(feature_size))\n",
    "        stdv = 1. / math.sqrt(feature_size)\n",
    "        self.Neighbor_weight.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "        x = input\n",
    "\n",
    "        gc = self.gc_list[0](x)\n",
    "        for i in range(1, self.K):\n",
    "            gc = torch.cat((gc, self.gc_list[i](x)), 1)\n",
    "            \n",
    "        combined = torch.cat((gc, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "\n",
    "        NC = torch.mul(Cell_State,  torch.mv(Variable(self.A_list[-1], requires_grad=False).cuda(), self.Neighbor_weight))\n",
    "        Cell_State = f * NC + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "\n",
    "        return Hidden_State, Cell_State, gc\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State, gc = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "        \n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.007080509793013334, valid_loss: 0.007259329780936241, time: [21.54], best model: 1\n",
      "Tested: L1_mean: 4.69242738537075, L1_std : 0.3852470692013615\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_dim, hidden_dim, output_dim, output_last = True)\n",
    "lstm, lstm_loss = TrainModel(lstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "lstm_test = TestModel(lstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.33400869369506836, valid_loss: 0.3300839066505432, time: [23.34], best model: 1\n",
      "Tested: L1_mean: 76.72123909455141, L1_std : 0.976383271040042\n"
     ]
    }
   ],
   "source": [
    "K = 64\n",
    "Clamp_A = False\n",
    "lsgclstm = LocalizedSpectralGraphConvolutionalLSTM(K, torch.Tensor(A), A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "lsgclstm, lsgclstm_loss = TrainModel(lsgclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "lsgclstm_test = TestModel(lsgclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample: 0.004999399185180664\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0045092105865478516\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.0059986114501953125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005507469177246094\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006001710891723633\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0045032501220703125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006005525588989258\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006005287170410156\n",
      "train sample: 0.0063402652740478516\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.0050127506256103516\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00700831413269043\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.007004499435424805\n",
      "train sample: 0.009506940841674805\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.004004240036010742\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0055084228515625\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005507707595825195\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.009000539779663086\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00600123405456543\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.0039980411529541016\n",
      "train sample: 0.005508899688720703\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.006002664566040039\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039980411529541016\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004001140594482422\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0040035247802734375\n",
      "train sample: 0.004004001617431641\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005004405975341797\n",
      "train sample: 0.005506992340087891\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.007018089294433594\n",
      "train sample: 0.00699615478515625\n",
      "train sample: 0.0069980621337890625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004509687423706055\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.010999917984008789\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.004003763198852539\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0049800872802734375\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003988027572631836\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.008000373840332031\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0045070648193359375\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.010000228881835938\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.006999492645263672\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003991603851318359\n",
      "train sample: 0.00450444221496582\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050048828125\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.004006624221801758\n",
      "train sample: 0.004510641098022461\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.004510164260864258\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005998134613037109\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.0063664913177490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.005449056625366211\n",
      "train sample: 0.006003618240356445\n",
      "train sample: 0.0055084228515625\n",
      "train sample: 0.009001016616821289\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005004405975341797\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.004503488540649414\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.008000373840332031\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005004405975341797\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005005598068237305\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.0045070648193359375\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.009177207946777344\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.0050048828125\n",
      "train sample: 0.008508920669555664\n",
      "train sample: 0.00700068473815918\n",
      "train sample: 0.014998435974121094\n",
      "train sample: 0.010999202728271484\n",
      "train sample: 0.014004707336425781\n",
      "train sample: 0.014508962631225586\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006001949310302734\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005110979080200195\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005507230758666992\n",
      "train sample: 0.0062351226806640625\n",
      "train sample: 0.0050051212310791016\n",
      "train sample: 0.0050182342529296875\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003981113433837891\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005507230758666992\n",
      "train sample: 0.0049896240234375\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.006003618240356445\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005511045455932617\n",
      "train sample: 0.00499725341796875\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005185604095458984\n",
      "train sample: 0.009002923965454102\n",
      "train sample: 0.004003763198852539\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004996299743652344\n",
      "train sample: 0.007004737854003906\n",
      "train sample: 0.005496978759765625\n",
      "train sample: 0.006004810333251953\n",
      "train sample: 0.006003856658935547\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.006015300750732422\n",
      "train sample: 0.005010843276977539\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.00600123405456543\n",
      "train sample: 0.006003618240356445\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005433559417724609\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.005062103271484375\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.0045108795166015625\n",
      "train sample: 0.00700068473815918\n",
      "train sample: 0.006201505661010742\n",
      "train sample: 0.00400853157043457\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.00500798225402832\n",
      "train sample: 0.003991842269897461\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.00899958610534668\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004257678985595703\n",
      "train sample: 0.004051923751831055\n",
      "train sample: 0.0049822330474853516\n",
      "train sample: 0.0051403045654296875\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.00544285774230957\n",
      "train sample: 0.0064394474029541016\n",
      "train sample: 0.005347251892089844\n",
      "train sample: 0.005507469177246094\n",
      "train sample: 0.005089998245239258\n",
      "train sample: 0.006196737289428711\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.006117343902587891\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.0076787471771240234\n",
      "train sample: 0.007999181747436523\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004081010818481445\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004504680633544922\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.005127429962158203\n",
      "train sample: 0.005506038665771484\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005483388900756836\n",
      "train sample: 0.005491733551025391\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005005598068237305\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.006351470947265625\n",
      "train sample: 0.003994464874267578\n",
      "train sample: 0.0075054168701171875\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004505157470703125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006813526153564453\n",
      "train sample: 0.006999492645263672\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005439281463623047\n",
      "train sample: 0.005413532257080078\n",
      "train sample: 0.005357027053833008\n",
      "train sample: 0.0069162845611572266\n",
      "train sample: 0.005509614944458008\n",
      "train sample: 0.007513284683227539\n",
      "train sample: 0.00506901741027832\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0050046443939208984\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.004001140594482422\n",
      "train sample: 0.008999347686767578\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004503011703491211\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.010999917984008789\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.00450587272644043\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0070040225982666016\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.0045053958892822266\n",
      "train sample: 0.005372762680053711\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0059986114501953125\n",
      "train sample: 0.0053653717041015625\n",
      "train sample: 0.00400233268737793\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00543975830078125\n",
      "train sample: 0.004004001617431641\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.008000612258911133\n",
      "train sample: 0.007998228073120117\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.013003826141357422\n",
      "train sample: 0.014505624771118164\n",
      "train sample: 0.013000011444091797\n",
      "train sample: 0.010999917984008789\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004003286361694336\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0041255950927734375\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.007297039031982422\n",
      "train sample: 0.006428718566894531\n",
      "train sample: 0.006384372711181641\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.008046865463256836\n",
      "train sample: 0.009505033493041992\n",
      "train sample: 0.009000301361083984\n",
      "train sample: 0.007001399993896484\n",
      "train sample: 0.005303859710693359\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.008119821548461914\n",
      "train sample: 0.005178689956665039\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005507707595825195\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.006999015808105469\n",
      "train sample: 0.009999752044677734\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.005502939224243164\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.005509376525878906\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.006502389907836914\n",
      "train sample: 0.007497549057006836\n",
      "train sample: 0.005448341369628906\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.009001970291137695\n",
      "train sample: 0.010015249252319336\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.00950932502746582\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0040018558502197266\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.008002281188964844\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00400233268737793\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.00422215461730957\n",
      "train sample: 0.003997087478637695\n",
      "train sample: 0.004003047943115234\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.00490260124206543\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.008207321166992188\n",
      "train sample: 0.00650787353515625\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.00718235969543457\n",
      "train sample: 0.006004810333251953\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005022764205932617\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050048828125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004004001617431641\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.009999275207519531\n",
      "train sample: 0.006998777389526367\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004505157470703125\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050046443939208984\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0040013790130615234\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006001710891723633\n",
      "train sample: 0.00900411605834961\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.008508920669555664\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005506038665771484\n",
      "train sample: 0.004988431930541992\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.007175445556640625\n",
      "train sample: 0.006509304046630859\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.0069904327392578125\n",
      "train sample: 0.005071163177490234\n",
      "train sample: 0.0050275325775146484\n",
      "train sample: 0.004967927932739258\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005066633224487305\n",
      "train sample: 0.005007505416870117\n",
      "train sample: 0.004940032958984375\n",
      "train sample: 0.010574579238891602\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004003763198852539\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0040018558502197266\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0045087337493896484\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.005503416061401367\n",
      "train sample: 0.0060045719146728516\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.00700068473815918\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.006018400192260742\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.0050046443939208984\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00600123405456543\n",
      "train sample: 0.003989219665527344\n",
      "train sample: 0.005129337310791016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.004507541656494141\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006415843963623047\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0049936771392822266\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.005993366241455078\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00600123405456543\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.0059833526611328125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004503965377807617\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00840449333190918\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.005507230758666992\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.008210420608520508\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.004980564117431641\n",
      "train sample: 0.006031036376953125\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0054128170013427734\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.009124279022216797\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.006507158279418945\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00600433349609375\n",
      "train sample: 0.00600123405456543\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006003618240356445\n",
      "train sample: 0.0058972835540771484\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0051212310791015625\n",
      "train sample: 0.005026817321777344\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005007743835449219\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005506753921508789\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.008998870849609375\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.00600433349609375\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004508018493652344\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.009999275207519531\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005506753921508789\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005009889602661133\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.005005836486816406\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005507707595825195\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.004461050033569336\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005997896194458008\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006509065628051758\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0049817562103271484\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.008208274841308594\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.0055086612701416016\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.00700068473815918\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00450444221496582\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.0052242279052734375\n",
      "train sample: 0.008999347686767578\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.005750894546508789\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005212306976318359\n",
      "train sample: 0.006003618240356445\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006003618240356445\n",
      "train sample: 0.0070078372955322266\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007000923156738281\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.00850820541381836\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.006998777389526367\n",
      "train sample: 0.006014585494995117\n",
      "train sample: 0.005991697311401367\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.0045320987701416016\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005004405975341797\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005004405975341797\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00593256950378418\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006176471710205078\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006999492645263672\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.005172252655029297\n",
      "train sample: 0.004613399505615234\n",
      "train sample: 0.0050048828125\n",
      "train sample: 0.004995584487915039\n",
      "train sample: 0.004956245422363281\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004505157470703125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.004376411437988281\n",
      "train sample: 0.004505634307861328\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006002664566040039\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.00450444221496582\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0059986114501953125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0045053958892822266\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.009000301361083984\n",
      "train sample: 0.009000778198242188\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004506111145019531\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0060024261474609375\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004001140594482422\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.0060040950775146484\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006013393402099609\n",
      "train sample: 0.005479574203491211\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004178285598754883\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0055124759674072266\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.007328033447265625\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.006009340286254883\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004033565521240234\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.006501436233520508\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.010999202728271484\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.015963315963745117\n",
      "train sample: 0.015000104904174805\n",
      "train sample: 0.013001203536987305\n",
      "train sample: 0.004997730255126953\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005004405975341797\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006502866744995117\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.009000539779663086\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.008000373840332031\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006002187728881836\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004506826400756836\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004506826400756836\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006003618240356445\n",
      "train sample: 0.0055084228515625\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.011003732681274414\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.010000467300415039\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004508018493652344\n",
      "train sample: 0.006011486053466797\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.006998777389526367\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.0071260929107666016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004506349563598633\n",
      "train sample: 0.004007816314697266\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.0050029754638671875\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005506038665771484\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.005005598068237305\n",
      "train sample: 0.004519939422607422\n",
      "train sample: 0.00499415397644043\n",
      "train sample: 0.003994941711425781\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003994464874267578\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00700068473815918\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0040051937103271484\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0039937496185302734\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.011530399322509766\n",
      "train sample: 0.015030622482299805\n",
      "train sample: 0.014000177383422852\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004001140594482422\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.004506587982177734\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039980411529541016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006423234939575195\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.008002042770385742\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005507707595825195\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006001710891723633\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004506349563598633\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.010000228881835938\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.005508899688720703\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00600433349609375\n",
      "train sample: 0.008018255233764648\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006014347076416016\n",
      "train sample: 0.004991054534912109\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006004810333251953\n",
      "train sample: 0.0049343109130859375\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.010003328323364258\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005004405975341797\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006998538970947266\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004925727844238281\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004154205322265625\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.007998943328857422\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0040035247802734375\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005989789962768555\n",
      "train sample: 0.0041942596435546875\n",
      "train sample: 0.0055081844329833984\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.008000612258911133\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0045087337493896484\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0050737857818603516\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.004992485046386719\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004003047943115234\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004003286361694336\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004022836685180664\n",
      "train sample: 0.0049326419830322266\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.004003286361694336\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0045087337493896484\n",
      "train sample: 0.008252382278442383\n",
      "train sample: 0.007999181747436523\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.004997730255126953\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005015134811401367\n",
      "train sample: 0.0049974918365478516\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0071222782135009766\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004003286361694336\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004004001617431641\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039980411529541016\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0045070648193359375\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00700068473815918\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.007004976272583008\n",
      "train sample: 0.004508018493652344\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.007482767105102539\n",
      "train sample: 0.009001016616821289\n",
      "train sample: 0.011070013046264648\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.009999513626098633\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004505634307861328\n",
      "train sample: 0.005193471908569336\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0050029754638671875\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004502534866333008\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004997730255126953\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.00600123405456543\n",
      "train sample: 0.0070018768310546875\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005506753921508789\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004002571105957031\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0040035247802734375\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.007020711898803711\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005147457122802734\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.006304025650024414\n",
      "train sample: 0.005198478698730469\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0049974918365478516\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004015445709228516\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005357503890991211\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005023956298828125\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.005505800247192383\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004001140594482422\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004040241241455078\n",
      "train sample: 0.0060405731201171875\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004330635070800781\n",
      "train sample: 0.005069255828857422\n",
      "train sample: 0.004506826400756836\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.008002281188964844\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005087852478027344\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.005005836486816406\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0060024261474609375\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.008999347686767578\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.00400233268737793\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.006002902984619141\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.01100015640258789\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004003047943115234\n",
      "train sample: 0.0045015811920166016\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0050048828125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004505634307861328\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0050029754638671875\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004994392395019531\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004002571105957031\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00800180435180664\n",
      "train sample: 0.008339643478393555\n",
      "train sample: 0.006108760833740234\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.012000083923339844\n",
      "train sample: 0.010000228881835938\n",
      "train sample: 0.018002748489379883\n",
      "train sample: 0.010505437850952148\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004087686538696289\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005192756652832031\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.00799870491027832\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005289316177368164\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.007505178451538086\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.007061004638671875\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0035054683685302734\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00699925422668457\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.007001399993896484\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007000923156738281\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0040013790130615234\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004003047943115234\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00402069091796875\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0045049190521240234\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00400233268737793\n",
      "train sample: 0.005049705505371094\n",
      "train sample: 0.004548788070678711\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.005038738250732422\n",
      "train sample: 0.006005048751831055\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004503726959228516\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005005359649658203\n",
      "train sample: 0.00399470329284668\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00450444221496582\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005005359649658203\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.00499415397644043\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004502296447753906\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.0035059452056884766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.01100468635559082\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00400543212890625\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.0050046443939208984\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004514932632446289\n",
      "train sample: 0.005005598068237305\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050051212310791016\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.00900578498840332\n",
      "train sample: 0.010999441146850586\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004994392395019531\n",
      "train sample: 0.008008003234863281\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.004993915557861328\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005005359649658203\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.009002685546875\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00400543212890625\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004994630813598633\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00400233268737793\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005005836486816406\n",
      "train sample: 0.004005908966064453\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.008000373840332031\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006997585296630859\n",
      "train sample: 0.006010293960571289\n",
      "train sample: 0.005005359649658203\n",
      "train sample: 0.0065155029296875\n",
      "train sample: 0.012000322341918945\n",
      "train sample: 0.015000104904174805\n",
      "train sample: 0.015000104904174805\n",
      "train sample: 0.014482975006103516\n",
      "train sample: 0.008994102478027344\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.00564265251159668\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005998134613037109\n",
      "train sample: 0.006507396697998047\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.006001710891723633\n",
      "train sample: 0.006001472473144531\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.011000394821166992\n",
      "train sample: 0.005005836486816406\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.005988121032714844\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004506349563598633\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00505375862121582\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004003047943115234\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0045070648193359375\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004992008209228516\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.009002923965454102\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500941276550293\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.00615382194519043\n",
      "train sample: 0.003991365432739258\n",
      "train sample: 0.003995180130004883\n",
      "train sample: 0.0039958953857421875\n",
      "train sample: 0.003996372222900391\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0060040950775146484\n",
      "train sample: 0.005501508712768555\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.0045049190521240234\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.01100015640258789\n",
      "train sample: 0.011000394821166992\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.011000394821166992\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.007002830505371094\n",
      "train sample: 0.005505084991455078\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00814199447631836\n",
      "train sample: 0.00400996208190918\n",
      "train sample: 0.009011030197143555\n",
      "train sample: 0.0039522647857666016\n",
      "train sample: 0.0075054168701171875\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005005359649658203\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.004994392395019531\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.007002115249633789\n",
      "train sample: 0.005005836486816406\n",
      "train sample: 0.005518198013305664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00399470329284668\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004994869232177734\n",
      "train sample: 0.00400543212890625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.005505800247192383\n",
      "train sample: 0.008000373840332031\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.010998964309692383\n",
      "train sample: 0.0059947967529296875\n",
      "train sample: 0.00913381576538086\n",
      "train sample: 0.006001949310302734\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.010999679565429688\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.011002540588378906\n",
      "train sample: 0.009999752044677734\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.008000373840332031\n",
      "train sample: 0.007994413375854492\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004994392395019531\n",
      "train sample: 0.0035028457641601562\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006999492645263672\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.008005380630493164\n",
      "train sample: 0.005011081695556641\n",
      "train sample: 0.007520437240600586\n",
      "train sample: 0.004994630813598633\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004994630813598633\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.009000301361083984\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004502773284912109\n",
      "train sample: 0.004005908966064453\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005994319915771484\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.010002374649047852\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007005453109741211\n",
      "train sample: 0.00399470329284668\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.010529756546020508\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006504058837890625\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.007001638412475586\n",
      "train sample: 0.0070056915283203125\n",
      "train sample: 0.004994869232177734\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.007002830505371094\n",
      "train sample: 0.007036685943603516\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0050106048583984375\n",
      "train sample: 0.004503488540649414\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.00499415397644043\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.012001991271972656\n",
      "train sample: 0.0060062408447265625\n",
      "train sample: 0.00950479507446289\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.010999917984008789\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.006505250930786133\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004503011703491211\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.01100015640258789\n",
      "train sample: 0.007010221481323242\n",
      "train sample: 0.005994558334350586\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.010999917984008789\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.006002902984619141\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0045049190521240234\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.011000394821166992\n",
      "train sample: 0.009007930755615234\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00400543212890625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00650477409362793\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006003141403198242\n",
      "train sample: 0.0045053958892822266\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003993988037109375\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004515171051025391\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0039980411529541016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004005908966064453\n",
      "train sample: 0.005994319915771484\n",
      "train sample: 0.003995180130004883\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004002571105957031\n",
      "train sample: 0.008644342422485352\n",
      "train sample: 0.009999513626098633\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.008001089096069336\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.011041879653930664\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005005598068237305\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.003994464874267578\n",
      "train sample: 0.0040056705474853516\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004994630813598633\n",
      "train sample: 0.00399470329284668\n",
      "train sample: 0.004994630813598633\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004994630813598633\n",
      "train sample: 0.004005908966064453\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.00901031494140625\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004002571105957031\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00450587272644043\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006999492645263672\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00400543212890625\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004505634307861328\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.006999492645263672\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00399470329284668\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.008002758026123047\n",
      "train sample: 0.015001296997070312\n",
      "train sample: 0.012003183364868164\n",
      "train sample: 0.01399993896484375\n",
      "train sample: 0.01399993896484375\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.005505800247192383\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.012000083923339844\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.010011434555053711\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.004004955291748047\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0060024261474609375\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00550532341003418\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.006036281585693359\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.009001493453979492\n",
      "train sample: 0.007002353668212891\n",
      "train sample: 0.007003068923950195\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.007994651794433594\n",
      "train sample: 0.005005836486816406\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.007011890411376953\n",
      "train sample: 0.004502773284912109\n",
      "train sample: 0.00450587272644043\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.005504608154296875\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.007999420166015625\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.010860919952392578\n",
      "train sample: 0.010999441146850586\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.005999088287353516\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.007505178451538086\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.012002944946289062\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.009002447128295898\n",
      "train sample: 0.004503011703491211\n",
      "train sample: 0.009999752044677734\n",
      "train sample: 0.010999679565429688\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007998228073120117\n",
      "train sample: 0.007001638412475586\n",
      "train sample: 0.008999824523925781\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.008001089096069336\n",
      "train sample: 0.006001949310302734\n",
      "train sample: 0.008013486862182617\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.003996372222900391\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.009000301361083984\n",
      "train sample: 0.009042024612426758\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004507303237915039\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.0059986114501953125\n",
      "train sample: 0.01100015640258789\n",
      "train sample: 0.010999441146850586\n",
      "train sample: 0.009999990463256836\n",
      "train sample: 0.011016130447387695\n",
      "train sample: 0.005004405975341797\n",
      "train sample: 0.004995584487915039\n",
      "train sample: 0.004005908966064453\n",
      "train sample: 0.004309415817260742\n",
      "train sample: 0.004997730255126953\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.004002571105957031\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.007001161575317383\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004288911819458008\n",
      "train sample: 0.005148410797119141\n",
      "train sample: 0.004007577896118164\n",
      "train sample: 0.004008054733276367\n",
      "train sample: 0.003997325897216797\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.004004240036010742\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0035109519958496094\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.010004043579101562\n",
      "train sample: 0.005996227264404297\n",
      "train sample: 0.007001638412475586\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.016000032424926758\n",
      "train sample: 0.015004158020019531\n",
      "train sample: 0.015026330947875977\n",
      "train sample: 0.005059480667114258\n",
      "train sample: 0.008936643600463867\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.0070018768310546875\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.0040018558502197266\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.006003379821777344\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0050051212310791016\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005017757415771484\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00800180435180664\n",
      "train sample: 0.006175041198730469\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.00450897216796875\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004004716873168945\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004507780075073242\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.0039980411529541016\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003997087478637695\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.008000850677490234\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.006003856658935547\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00516510009765625\n",
      "train sample: 0.0059909820556640625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0035088062286376953\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004509687423706055\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.008011579513549805\n",
      "train sample: 0.007999420166015625\n",
      "train sample: 0.007000923156738281\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.011003494262695312\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004508018493652344\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.009510040283203125\n",
      "train sample: 0.011005163192749023\n",
      "train sample: 0.006998538970947266\n",
      "train sample: 0.014000654220581055\n",
      "train sample: 0.014000415802001953\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.004018306732177734\n",
      "train sample: 0.0040018558502197266\n",
      "train sample: 0.003987789154052734\n",
      "train sample: 0.005998134613037109\n",
      "train sample: 0.008000850677490234\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.003000020980834961\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004997730255126953\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004002571105957031\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003991842269897461\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.009999752044677734\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00550532341003418\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.005306243896484375\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0049915313720703125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0070018768310546875\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.005006074905395508\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.007003307342529297\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004007101058959961\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.012992143630981445\n",
      "train sample: 0.012967109680175781\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004002809524536133\n",
      "train sample: 0.007998943328857422\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.00899958610534668\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004997730255126953\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.010985851287841797\n",
      "train sample: 0.006508588790893555\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006001710891723633\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004997968673706055\n",
      "train sample: 0.004004001617431641\n",
      "train sample: 0.004504203796386719\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.006001710891723633\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004254579544067383\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004001140594482422\n",
      "train sample: 0.003993034362792969\n",
      "train sample: 0.004961729049682617\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006135702133178711\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.007505893707275391\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.010999679565429688\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.007003068923950195\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004505634307861328\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004013538360595703\n",
      "train sample: 0.0039937496185302734\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.00400090217590332\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004003763198852539\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005980968475341797\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.004004240036010742\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005516529083251953\n",
      "train sample: 0.004990339279174805\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.0060040950775146484\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004003286361694336\n",
      "train sample: 0.0046651363372802734\n",
      "train sample: 0.004038333892822266\n",
      "train sample: 0.0050048828125\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006999015808105469\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.006999492645263672\n",
      "train sample: 0.008003711700439453\n",
      "train sample: 0.004508018493652344\n",
      "train sample: 0.006999969482421875\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.009998559951782227\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.0075092315673828125\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.009392261505126953\n",
      "train sample: 0.0060176849365234375\n",
      "train sample: 0.004987478256225586\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.009001016616821289\n",
      "train sample: 0.00500941276550293\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.0040035247802734375\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0045092105865478516\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005003213882446289\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004003047943115234\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004508495330810547\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500178337097168\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004988431930541992\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0040035247802734375\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00400233268737793\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006002187728881836\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003998279571533203\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006998777389526367\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.008000850677490234\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.007002115249633789\n",
      "train sample: 0.007999658584594727\n",
      "train sample: 0.014999866485595703\n",
      "train sample: 0.015508413314819336\n",
      "train sample: 0.013999462127685547\n",
      "train sample: 0.00899958610534668\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00540614128112793\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006001472473144531\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.00400543212890625\n",
      "train sample: 0.00399470329284668\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0040056705474853516\n",
      "train sample: 0.0050051212310791016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005005359649658203\n",
      "train sample: 0.004956245422363281\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.004954814910888672\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.0059986114501953125\n",
      "train sample: 0.003998517990112305\n",
      "train sample: 0.007999420166015625\n",
      "train sample: 0.007003068923950195\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039975643157958984\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005212545394897461\n",
      "train sample: 0.008364677429199219\n",
      "train sample: 0.00400233268737793\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005095720291137695\n",
      "train sample: 0.005177021026611328\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005001068115234375\n",
      "train sample: 0.004995107650756836\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006003856658935547\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005506038665771484\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0070078372955322266\n",
      "train sample: 0.004503488540649414\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.009000062942504883\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.007999897003173828\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.007002353668212891\n",
      "train sample: 0.009000539779663086\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.008999109268188477\n",
      "train sample: 0.014999866485595703\n",
      "train sample: 0.015000104904174805\n",
      "train sample: 0.00950479507446289\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.0039980411529541016\n",
      "train sample: 0.007001161575317383\n",
      "train sample: 0.006001949310302734\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.011002302169799805\n",
      "train sample: 0.010999679565429688\n",
      "train sample: 0.0048675537109375\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004039287567138672\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.005002260208129883\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005032539367675781\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004144430160522461\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006002664566040039\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0045053958892822266\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.00699925422668457\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.00600123405456543\n",
      "Epoch: 0, train_loss: 0.027590300887823105, valid_loss: 0.026917409151792526, time: [34.65], best model: 1\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0040035247802734375\n",
      "train sample: 0.004995822906494141\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.0050051212310791016\n",
      "train sample: 0.005006313323974609\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.0050280094146728516\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006001949310302734\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005109071731567383\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004556179046630859\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.009001493453979492\n",
      "train sample: 0.005002737045288086\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00950479507446289\n",
      "train sample: 0.012000322341918945\n",
      "train sample: 0.010999917984008789\n",
      "train sample: 0.011000394821166992\n",
      "train sample: 0.01399993896484375\n",
      "train sample: 0.014999866485595703\n",
      "train sample: 0.01020050048828125\n",
      "train sample: 0.005010366439819336\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.003507852554321289\n",
      "train sample: 0.0050089359283447266\n",
      "train sample: 0.004991292953491211\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.0060007572174072266\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.005987644195556641\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0040035247802734375\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005003929138183594\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004998445510864258\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.0069997310638427734\n",
      "train sample: 0.010000467300415039\n",
      "train sample: 0.010999679565429688\n",
      "train sample: 0.00800013542175293\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004504203796386719\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005999565124511719\n",
      "train sample: 0.00700068473815918\n",
      "train sample: 0.005999326705932617\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0040013790130615234\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005003690719604492\n",
      "train sample: 0.004000425338745117\n",
      "train sample: 0.004502773284912109\n",
      "train sample: 0.005003452301025391\n",
      "train sample: 0.005009889602661133\n",
      "train sample: 0.003991127014160156\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.0041196346282958984\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.0040090084075927734\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005018711090087891\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.007003068923950195\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.008507966995239258\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.009000539779663086\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.006000518798828125\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004502534866333008\n",
      "train sample: 0.003997802734375\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.01100015640258789\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.009001016616821289\n",
      "train sample: 0.005002498626708984\n",
      "train sample: 0.004001617431640625\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004507780075073242\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005002021789550781\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004998683929443359\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.008000373840332031\n",
      "train sample: 0.003998994827270508\n",
      "train sample: 0.003999471664428711\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.0060024261474609375\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004503011703491211\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.009386062622070312\n",
      "train sample: 0.010999202728271484\n",
      "train sample: 0.00600123405456543\n",
      "train sample: 0.004007816314697266\n",
      "train sample: 0.004011631011962891\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.00499725341796875\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0055086612701416016\n",
      "train sample: 0.0039980411529541016\n",
      "train sample: 0.005998373031616211\n",
      "train sample: 0.004998207092285156\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0040018558502197266\n",
      "train sample: 0.006314516067504883\n",
      "train sample: 0.005372047424316406\n",
      "train sample: 0.007474184036254883\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.006001472473144531\n",
      "train sample: 0.0049991607666015625\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.006000041961669922\n",
      "train sample: 0.003000020980834961\n",
      "train sample: 0.004998922348022461\n",
      "train sample: 0.007000446319580078\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.005504131317138672\n",
      "train sample: 0.005001544952392578\n",
      "train sample: 0.0060002803802490234\n",
      "train sample: 0.005998373031616211\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.003999233245849609\n",
      "train sample: 0.004999637603759766\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006004810333251953\n",
      "train sample: 0.0039997100830078125\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.004510402679443359\n",
      "train sample: 0.006001472473144531\n",
      "train sample: 0.0050013065338134766\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.005000591278076172\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.004999399185180664\n",
      "train sample: 0.004000186920166016\n",
      "train sample: 0.005000114440917969\n",
      "train sample: 0.005004167556762695\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004002094268798828\n",
      "train sample: 0.004506587982177734\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004000663757324219\n",
      "train sample: 0.00599980354309082\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.005998373031616211\n",
      "train sample: 0.0050008296966552734\n",
      "train sample: 0.005998849868774414\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.004999876022338867\n",
      "train sample: 0.00500035285949707\n",
      "train sample: 0.003999948501586914\n",
      "train sample: 0.006000995635986328\n",
      "train sample: 0.003998756408691406\n",
      "train sample: 0.006003618240356445\n",
      "train sample: 0.0070002079010009766\n",
      "train sample: 0.003999948501586914\n",
      "Tested: L1_mean: 6.101380631671195, L1_std : 0.5977019759142242\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "back_length = 3\n",
    "Clamp_A = False\n",
    "sgclstm = SpectralGraphConvolutionalLSTM(K, torch.Tensor(A), A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "sgclstm, sgclstm_loss = TrainModel(sgclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "sgclstm_test = TestModel(sgclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "back_length = 3\n",
    "Clamp_A = False\n",
    "gclstm = GraphConvolutionalLSTM(K, torch.Tensor(A), FFR[back_length], A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "gclstm, gclstm_loss = TrainModel(gclstm, train_dataloader, valid_dataloader, num_epochs = 1)\n",
    "gclstm_test = TestModel(gclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn_val_loss = np.asarray(rnn_loss[3])\n",
    "\n",
    "#print(lsgclstm_loss)\n",
    "#print([tensor.item() for tensor, _ in lstm_loss])\n",
    "lstm_val_loss = np.asarray(torch.stack(lstm_loss[0]).tolist())\n",
    "hgclstm_val_loss = np.asarray(torch.stack(gclstm_loss[0]).tolist())\n",
    "lsgclstm_val_loss = np.asarray(torch.stack(lsgclstm_loss[0]).tolist())\n",
    "sgclstm_val_loss = np.asarray(torch.stack(sgclstm_loss[0]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_val_loss = np.load('lstm_val_loss.npy')\n",
    "# hgclstm_val_loss = np.load('hgclstm_val_loss.npy')\n",
    "# lsgclstm_val_loss = np.load('lsgclstm_val_loss.npy')\n",
    "# sgclstm_val_loss = np.load('sgclstm_val_loss.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lstm_val_loss', lstm_val_loss)\n",
    "np.save('hgclstm_val_loss', hgclstm_val_loss)\n",
    "np.save('lsgclstm_val_loss', lsgclstm_val_loss)\n",
    "np.save('sgclstm_val_loss', sgclstm_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.plot(lstm_val_loss,  label = 'LSTM')\n",
    "plt.plot(sgclstm_val_loss,  label = 'SGC+LSTM')\n",
    "plt.plot(lsgclstm_val_loss,  label = 'LSGC+LSTM')\n",
    "plt.plot(hgclstm_val_loss,  label = 'HGC-LSTM')\n",
    "plt.ylim((6 * 0.0001, 0.4))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Validation Loss (MSE)', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, which='both')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('Validation_loss.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
